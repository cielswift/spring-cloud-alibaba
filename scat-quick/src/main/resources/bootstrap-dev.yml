spring:
  #分库分表
  shardingsphere:
    datasource:
      names: ds0,ds1,ds2 #数据源名称，多数据源以逗号分隔
      ds0:
        type: com.alibaba.druid.pool.DruidDataSource
        initialSize: 16
        minIdle: 16
        maxActive: 32
        driver-class-name: com.mysql.jdbc.Driver
        url: jdbc:mysql://127.0.0.1:1670/spring_alibaba?seUnicode=true&characterEncoding=UTF-8&useSSL=false&serverTimezone=Asia/Shanghai
        username: root
        password: ciel
      ds1:
        type: com.alibaba.druid.pool.DruidDataSource
        initialSize: 16
        minIdle: 16
        maxActive: 32
        driver-class-name: com.mysql.jdbc.Driver
        url: jdbc:mysql://127.0.0.1:1671/spring_alibaba?seUnicode=true&characterEncoding=UTF-8&useSSL=false&serverTimezone=Asia/Shanghai
        username: root
        password: ciel
      ds2:
        type: com.alibaba.druid.pool.DruidDataSource
        initialSize: 16
        minIdle: 16
        maxActive: 32
        driver-class-name: com.mysql.jdbc.Driver
        url: jdbc:mysql://127.0.0.1:1672/spring_alibaba?seUnicode=true&characterEncoding=UTF-8&useSSL=false&serverTimezone=Asia/Shanghai
        username: root
        password: ciel
    sharding:
      tables:
        sca_girls:
          actual-data-nodes: ds$->{0..2}.sca_girls$->{0..1} #由数据源名 + 表名组成，以小数点分隔。多个表以逗号分隔，支持inline表达式。缺省表示使用已知数据源与逻辑表名称生成数据节点
          database-strategy: #分库策略
            inline:
              sharding-column: ID #分片列名称
              algorithm-expression: ds$->{ID % 3}
              #standard:
              #sharding-column: ID
              #precise-algorithm-class-name: com.ciel.scatquick.sharding.ExactSelectAlgorithm  #精确分片算法类名称，用于=和IN。该类需实现PreciseShardingAlgorithm接口并提供无参数的构造器
              #range-algorithm-class-name: com.ciel.scatquick.sharding.RangeSelectAlgorithm #范围分片算法类名称，用于BETWEEN，可选。该类需实现RangeShardingAlgorithm接口并提供无参数的构造器
          table-strategy: #分表策略
            inline:
              sharding-column: ID
              algorithm-expression: sca_girls$->{ID % 2}
      #          key-generator:
      #          column: #自增列名称，缺省表示不使用自增主键生成器
      #          type: #自增列值生成器类型，缺省表示使用默认自增列值生成器。可使用用户自定义的列值生成器或选择内置类型：SNOWFLAKE/UUID
      #          props: #属性配置, 注意：使用SNOWFLAKE算法，需要配置worker.id与max.tolerate.time.difference.milliseconds属性。若使用此算法生成值作分片值，建议配置max.vibration.offset属性
      #            max:
      #              vibration:
      #                offset:
      default-data-source-name: ds0  #未配置分片规则的表将通过默认数据源定位
      broadcast-tables: sca_dict  #公共表 两个库中的数据是一样的 如字典表
      #读写分离
    #      master-slave-rules:
    #        dufl1: #逻辑名称
    #          master-data-source-name: ds0   #主库数据源名称
    #          slave-data-source-names[0]: ds1 #从库数据源名称列表
    #          #slave-data-source-names[1]: ds2
    #          load-balance-algorithm-class-name: org.apache.shardingsphere.core.strategy.masterslave.RoundRobinMasterSlaveLoadBalanceAlgorithm #从库负载均衡算法类名称。该类需实现MasterSlaveLoadBalanceAlgorithm接口且提供无参数构造器
    #          load-balancer-name: xiapeixin #从库负载均衡算法名称
    props:
      sql:
        show: true #是否开启SQL显示，默认值: false
      executor:
        size: 8 #工作线程数量，默认值: CPU核数
      check:
        table:
          metadata:
            enabled: false #是否在启动时检查分表元数据一致性，默认值: false
#    rules:
#      master-slave:
#        type:

#  #分库策略，缺省表示使用默认分库策略，以下的分片策略只能选其一
#  #用于单分片键的标准分片场景
#  spring.shardingsphere.sharding.tables.<logic-table-name>.database-strategy.standard.sharding-column=
#  spring.shardingsphere.sharding.tables.<logic-table-name>.database-strategy.standard.precise-algorithm-class-name= #精确分片算法类名称，用于=和IN。该类需实现PreciseShardingAlgorithm接口并提供无参数的构造器
#  spring.shardingsphere.sharding.tables.<logic-table-name>.database-strategy.standard.range-algorithm-class-name=
#
#  #用于多分片键的复合分片场景
#  spring.shardingsphere.sharding.tables.<logic-table-name>.database-strategy.complex.sharding-columns= #分片列名称，多个列以逗号分隔
#  spring.shardingsphere.sharding.tables.<logic-table-name>.database-strategy.complex.algorithm-class-name= #复合分片算法类名称。该类需实现ComplexKeysShardingAlgorithm接口并提供无参数的构造器
#
#  #行表达式分片策略
#  spring.shardingsphere.sharding.tables.<logic-table-name>.database-strategy.inline.sharding-column= #分片列名称
#  spring.shardingsphere.sharding.tables.<logic-table-name>.database-strategy.inline.algorithm-expression= #分片算法行表达式，需符合groovy语法
#
#  #Hint分片策略
#  spring.shardingsphere.sharding.tables.<logic-table-name>.database-strategy.hint.algorithm-class-name= #Hint分片算法类名称。该类需实现HintShardingAlgorithm接口并提供无参数的构造器
#
#  #分表策略，同分库策略
#  spring.shardingsphere.sharding.tables.<logic-table-name>.table-strategy.xxx= #省略
#
#  spring.shardingsphere.sharding.binding-tables[0]= #绑定表规则列表
#  spring.shardingsphere.sharding.binding-tables[1]= #绑定表规则列表
#  spring.shardingsphere.sharding.binding-tables[x]= #绑定表规则列表
#
#  spring.shardingsphere.sharding.broadcast-tables[0]= #广播表规则列表
#  spring.shardingsphere.sharding.broadcast-tables[1]= #广播表规则列表
#  spring.shardingsphere.sharding.broadcast-tables[x]= #广播表规则列表
#
#  spring.shardingsphere.sharding.default-data-source-name= #未配置分片规则的表将通过默认数据源定位
#  spring.shardingsphere.sharding.default-database-strategy.xxx= #默认数据库分片策略，同分库策略
#  spring.shardingsphere.sharding.default-table-strategy.xxx= #默认表分片策略，同分表策略
#  spring.shardingsphere.sharding.default-key-generator.type= #默认自增列值生成器类型，缺省将使用org.apache.shardingsphere.core.keygen.generator.impl.SnowflakeKeyGenerator。可使用用户自定义的列值生成器或选择内置类型：SNOWFLAKE/UUID
#  spring.shardingsphere.sharding.default-key-generator.props.<property-name>= #自增列值生成器属性配置, 比如SNOWFLAKE算法的worker.id与max.tolerate.time.difference.milliseconds
#
#  spring.shardingsphere.sharding.master-slave-rules.<master-slave-data-source-name>.master-data-source-name= #详见读写分离部分
#  spring.shardingsphere.sharding.master-slave-rules.<master-slave-data-source-name>.slave-data-source-names[0]= #详见读写分离部分
#  spring.shardingsphere.sharding.master-slave-rules.<master-slave-data-source-name>.slave-data-source-names[1]= #详见读写分离部分
#  spring.shardingsphere.sharding.master-slave-rules.<master-slave-data-source-name>.slave-data-source-names[x]= #详见读写分离部分
#  spring.shardingsphere.sharding.master-slave-rules.<master-slave-data-source-name>.load-balance-algorithm-class-name= #详见读写分离部分
#  spring.shardingsphere.sharding.master-slave-rules.<master-slave-data-source-name>.load-balance-algorithm-type= #详见读写分离部分


# kafka----------------------------------------------------------------------------------------------
#  kafka:
#    # 指定kafka server的地址，集群配多个，中间，逗号隔开
#    bootstrap-servers: hadoop.master:9920,hadoop.slave1:9920,hadoop.slave2:9920
#
#    # 写入失败时，重试次数。当leader节点失效，一个repli节点会替代成为leader节点，此时可能出现写入失败，
#    # 当retris为0时，produce不会重复。retirs重发，此时repli节点完全成为leader节点，不会产生消息丢失。
#    producer:
#      retries: 0
#      batch-size: 16384   # 每次批量发送消息的数量,produce积累到一定数据，一次发送
#      buffer-memory: 33554432 # produce积累数据一次发送，缓存大小达到buffer.memory就发送数据
#      acks: 1
#      key-serializer: org.apache.kafka.common.serialization.StringSerializer
#      value-serializer: org.apache.kafka.common.serialization.StringSerializer
#    #procedure要求leader在考虑完成请求之前收到的确认数，用于控制发送记录在服务端的持久化，其值可以为如下：
#    #acks = 0 如果设置为零，则生产者将不会等待来自服务器的任何确认，该记录将立即添加到套接字缓冲区并视为已发送。在这种情况下，无法保证服务器已收到记录，并且重试配置将不会生效（因为客户端通常不会知道任何故障），为每条记录返回的偏移量始终设置为-1。
#    #acks = 1 这意味着leader会将记录写入其本地日志，但无需等待所有副本服务器的完全确认即可做出回应，在这种情况下，如果leader在确认记录后立即失败，但在将数据复制到所有的副本服务器之前，则记录将会丢失。
#    #acks = all 这意味着leader将等待完整的同步副本集以确认记录，这保证了只要至少一个同步副本服务器仍然存活，记录就不会丢失，这是最强有力的保证，这相当于acks = -1的设置。
#    #可以设置的值为：all, -1, 0, 1
#
#    # 指定消息key和消息体的编解码方式
#
#    consumer:
#      group-id: ciel-group # 指定默认消费者group id --> 由于在kafka中，同一组中的consumer不会读取到同一个消息，依靠groud.id设置组名
#
#      #earliest 当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费
#      #latest 当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产生的该分区下的数据
#      #none topic各分区都存在已提交的offset时，从offset后开始消费；只要有一个分区不存在已提交的offset，则抛出异常
#      auto-offset-reset: earliest
#      enable-auto-commit: true # enable.auto.commit:true --> 设置自动提交offset
#      auto-commit-interval: 100 #如果'enable.auto.commit'为true，则消费者偏移自动提交给Kafka的频率（以毫秒为单位），默认值为5000
#      # 指定消息key和消息体的编解码方式
#      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
#      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer